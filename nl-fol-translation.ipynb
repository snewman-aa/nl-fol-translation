{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_YUAoBh3kfkJ",
    "outputId": "f04223b2-2fcf-455b-c223-5aa10080caba"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hiJySc29kmhA",
    "outputId": "714ce953-38cf-4447-fa58-d0ce5431bf31"
   },
   "outputs": [],
   "source": [
    "# hyperdimensional embeddings\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "from datasets import load_dataset\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "EMBEDDING_DIM = 1024\n",
    "SEED = 42\n",
    "DATASET_NAME = \"yuan-yang/MALLS-v0\"\n",
    "SPLIT = \"train\"\n",
    "\n",
    "PLACEHOLDER_TO_SYMBOL = {\n",
    "    \"[forall]\": \"∀\",\n",
    "    \"[exists]\": \"∃\",\n",
    "    \"[not]\": \"¬\",\n",
    "    \"[implies]\": \"→\",\n",
    "    \"[and]\": \"∧\",\n",
    "    \"[or]\": \"∨\",\n",
    "    \"[oplus]\": \"⊕\",\n",
    "    \"[iff]\": \"↔\",\n",
    "}\n",
    "\n",
    "SYMBOL_TO_PLACEHOLDER = {v: k for k, v in PLACEHOLDER_TO_SYMBOL.items()}\n",
    "\n",
    "def generate_random_vector(dim, seed):\n",
    "    \"\"\"\n",
    "    Generate a random bipolar vector of dimension 'dim' with elements -1 or 1.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.choice([-1, 1], size=dim)\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        dataset = load_dataset(DATASET_NAME, split=SPLIT)\n",
    "        logger.info(f\"Loaded dataset '{DATASET_NAME}' with split '{SPLIT}' containing {len(dataset)} examples.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading dataset '{DATASET_NAME}': {e}\")\n",
    "        return\n",
    "\n",
    "    # Unique symbols\n",
    "    predicates = set()\n",
    "    variables = set()\n",
    "    constants = set()\n",
    "    operators = set()\n",
    "\n",
    "    # Parse the FOL to extract unique predicates, variables, constants, and operators\n",
    "    for idx, example in enumerate(dataset):\n",
    "        fol = example.get('FOL', '')\n",
    "        if not fol:\n",
    "            logger.warning(f\"Empty FOL expression at index {idx}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Replace placeholders with actual symbols\n",
    "        for ph, sym in PLACEHOLDER_TO_SYMBOL.items():\n",
    "            fol = fol.replace(ph, sym)\n",
    "\n",
    "        # Simple parsing\n",
    "        tokens = fol.replace('(', ' ').replace(')', ' ').replace(',', ' ').split()\n",
    "        for token in tokens:\n",
    "            if token in SYMBOL_TO_PLACEHOLDER.values() or token in SYMBOL_TO_PLACEHOLDER:\n",
    "                operators.add(token)\n",
    "            elif token.islower():\n",
    "                variables.add(token)\n",
    "            elif token[0].isupper() and token[1:].islower():\n",
    "                predicates.add(token)\n",
    "            else:\n",
    "                constants.add(token)\n",
    "\n",
    "    logger.info(f\"Extracted {len(predicates)} predicates, {len(variables)} variables, {len(constants)} constants, and {len(operators)} operators.\")\n",
    "\n",
    "    #---SYMBOL EMBEDDINGS---#\n",
    "\n",
    "    symbol_embeddings = {}\n",
    "\n",
    "    # Generate embeddings for operators and quantifiers\n",
    "    operators_list = list(operators)\n",
    "    quantifiers = [\"∀\", \"∃\"]\n",
    "    operators_extended = operators_list + quantifiers\n",
    "\n",
    "    for sym in operators_extended:\n",
    "        seed = SEED + hash(sym) % 1000\n",
    "        symbol_embeddings[sym] = generate_random_vector(EMBEDDING_DIM, seed=seed)\n",
    "\n",
    "    # Generate embeddings for predicates\n",
    "    for pred in predicates:\n",
    "        seed = SEED + hash(pred) % 1000\n",
    "        symbol_embeddings[pred] = generate_random_vector(EMBEDDING_DIM, seed=seed)\n",
    "\n",
    "    # Generate embeddings for variables\n",
    "    for var in variables:\n",
    "        seed = SEED + hash(var) % 1000\n",
    "        symbol_embeddings[var] = generate_random_vector(EMBEDDING_DIM, seed=seed)\n",
    "\n",
    "    # Generate embeddings for constants\n",
    "    for const in constants:\n",
    "        seed = SEED + hash(const) % 1000\n",
    "        symbol_embeddings[const] = generate_random_vector(EMBEDDING_DIM, seed=seed)\n",
    "\n",
    "    # Save symbol embeddings\n",
    "    os.makedirs(\"hyperdimensional_embeddings\", exist_ok=True)\n",
    "    np.save(\"hyperdimensional_embeddings/symbol_embeddings.npy\", symbol_embeddings)\n",
    "    logger.info(\"Saved 'symbol_embeddings.npy' successfully.\")\n",
    "\n",
    "    #---TYPE EMBEDDINGS---#\n",
    "\n",
    "    type_embeddings = {}\n",
    "\n",
    "    # Define types including 'predicate'\n",
    "    types = ['quantifier', 'variable', 'constant', 'operator', 'predicate']\n",
    "\n",
    "    for typ in types:\n",
    "        seed = SEED + hash(typ) % 1000\n",
    "        type_embeddings[typ] = generate_random_vector(EMBEDDING_DIM, seed=seed)\n",
    "\n",
    "    np.save(\"hyperdimensional_embeddings/type_embeddings.npy\", type_embeddings)\n",
    "    logger.info(\"Saved 'type_embeddings.npy' successfully.\")\n",
    "\n",
    "    with open(\"hyperdimensional_embeddings/variables.txt\", \"w\") as f:\n",
    "        for var in variables:\n",
    "            f.write(f\"{var}\\n\")\n",
    "    logger.info(\"Saved 'variables.txt' successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMhtzG29knUl",
    "outputId": "b95b683c-e5d4-4c08-9d00-2751ebb9baec"
   },
   "outputs": [],
   "source": [
    "# constrained decoding\n",
    "\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.generation.logits_process import LogitsProcessor, LogitsProcessorList\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_REPO = \"snewmanaa/flan-t5-NL-FOL-baseline\"\n",
    "MAX_LENGTH = 128\n",
    "BEAM_SIZE = 5  # Ensure BEAM_SIZE is set to an integer\n",
    "\n",
    "SYMBOL_TO_PLACEHOLDER = {\n",
    "    \"∀\": \"[forall]\",\n",
    "    \"∃\": \"[exists]\",\n",
    "    \"¬\": \"[not]\",\n",
    "    \"→\": \"[implies]\",\n",
    "    \"∧\": \"[and]\",\n",
    "    \"∨\": \"[or]\",\n",
    "    \"⊕\": \"[oplus]\",\n",
    "    \"↔\": \"[iff]\",\n",
    "}\n",
    "\n",
    "PLACEHOLDER_TO_SYMBOL = {v: k for k, v in SYMBOL_TO_PLACEHOLDER.items()}\n",
    "\n",
    "def load_variables(file_path=\"hyperdimensional_embeddings/variables.txt\"):\n",
    "    \"\"\"\n",
    "    Load variables list from the text file saved in step 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            variables = [line.strip() for line in f.readlines()]\n",
    "        logger.info(f\"Loaded {len(variables)} variables from '{file_path}'.\")\n",
    "        return variables\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading variables from '{file_path}': {e}\")\n",
    "        return []\n",
    "\n",
    "def postprocess(decoded_texts):\n",
    "    \"\"\"\n",
    "    Replace placeholders with original symbols\n",
    "    \"\"\"\n",
    "    restored_texts = []\n",
    "    for text in decoded_texts:\n",
    "        for ph, sym in PLACEHOLDER_TO_SYMBOL.items():\n",
    "            text = text.replace(ph, sym)\n",
    "        restored_texts.append(text)\n",
    "    return restored_texts\n",
    "\n",
    "class QuantifierFollowProcessor(LogitsProcessor):\n",
    "    \"\"\"\n",
    "    Custom LogitsProcessor to enforce that quantifiers are followed by variables\n",
    "    \"\"\"\n",
    "    def __init__(self, quantifier_ids, variable_ids, device):\n",
    "        super().__init__()\n",
    "        self.quantifier_ids = quantifier_ids\n",
    "        self.variable_ids = variable_ids\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        # Last generated\n",
    "        last_token_ids = input_ids[:, -1]\n",
    "\n",
    "        # Create a mask where the last token is a quantifier\n",
    "        is_quantifier = torch.zeros_like(last_token_ids, dtype=torch.bool)\n",
    "        for q_id in self.quantifier_ids:\n",
    "            is_quantifier = is_quantifier | (last_token_ids == q_id)\n",
    "\n",
    "        # For each sequence where the last token is a quantifier,\n",
    "        # set all logits to -inf except for variable_ids to prevent\n",
    "        # ouputing anything other than a variable\n",
    "        for i, flag in enumerate(is_quantifier):\n",
    "            if flag:\n",
    "                scores[i] = torch.full_like(scores[i], -float(\"inf\"))\n",
    "                # Allow only variable_ids\n",
    "                scores[i, self.variable_ids] = 0.0\n",
    "\n",
    "        return scores\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(MODEL_REPO)\n",
    "        model = T5ForConditionalGeneration.from_pretrained(MODEL_REPO)\n",
    "        logger.info(f\"Loaded model '{MODEL_REPO}' successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model '{MODEL_REPO}': {e}\")\n",
    "        return\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    logger.info(f\"Model moved to {device}.\")\n",
    "\n",
    "    quantifiers = [\"[forall]\", \"[exists]\"]\n",
    "\n",
    "    variables = load_variables()\n",
    "    if not variables:\n",
    "        logger.error(\"No variables loaded. Make sure you've run hyperdimensional_embeddings\")\n",
    "        return\n",
    "\n",
    "    # Convert tokens to IDs\n",
    "    quantifier_ids = tokenizer.convert_tokens_to_ids(quantifiers)\n",
    "    variable_ids = tokenizer.convert_tokens_to_ids(variables)\n",
    "\n",
    "    logger.debug(f\"Quantifier IDs: {quantifier_ids}\")\n",
    "    logger.debug(f\"Variable IDs: {variable_ids}\")\n",
    "\n",
    "    # Initialize custom logits processor\n",
    "    custom_processor = QuantifierFollowProcessor(quantifier_ids, variable_ids, device)\n",
    "    custom_processors = LogitsProcessorList([custom_processor])\n",
    "\n",
    "    #---EXAMPLE INPUT---#\n",
    "    nl_sentence = \"Every student loves some course.\"\n",
    "    input_text = \"Translate English to FOL: \" + nl_sentence\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    logger.info(f\"Input Text: {input_text}\")\n",
    "    logger.debug(f\"Input IDs: {input_ids}\")\n",
    "\n",
    "    logger.info(\"Generating FOL with constrained decoding...\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=MAX_LENGTH,\n",
    "                num_beams=BEAM_SIZE,\n",
    "                logits_processor=custom_processors,\n",
    "                early_stopping=True,\n",
    "                return_dict_in_generate=False,\n",
    "                output_scores=False,\n",
    "                output_hidden_states=False\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during generation: {e}\")\n",
    "        return\n",
    "\n",
    "    # Decode and postprocess\n",
    "    try:\n",
    "        decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        final_output = postprocess([decoded_output])[0]\n",
    "        logger.info(f\"Generated FOL: {final_output}\")\n",
    "        print(\"Generated FOL:\", final_output)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during decoding: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1s8qUBZkpLZ",
    "outputId": "a797d383-389e-4da4-87d2-ed654d5443a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded model 'snewmanaa/flan-t5-NL-FOL-baseline' successfully.\n",
      "INFO:__main__:Model moved to cuda.\n",
      "INFO:__main__:Loaded hyperdimensional embeddings successfully.\n",
      "INFO:__main__:Loaded 620 variables from 'hyperdimensional_embeddings/variables.txt'.\n",
      "INFO:__main__:Variable IDs: [2, 2, 2, 26, 4250, 7325, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 19747, 2, 2, 2, 22288, 2, 2, 2, 2, 2, 2, 2, 15974, 2, 107, 2, 2, 20779, 2, 2256, 2, 2, 20113, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3009, 2, 5842, 2, 2, 2, 2, 2, 2, 63, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1135, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 29, 2, 28188, 2, 2, 2, 2, 14700, 20309, 2, 2, 2, 2857, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7149, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5556, 2, 6075, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2242, 2, 2, 26809, 2, 2, 6633, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2138, 2, 2, 2, 2, 2, 5165, 2, 2, 2, 2, 8115, 2, 2, 2, 2, 2, 2, 2, 6779, 2, 2, 2, 2, 2, 2, 2, 2, 15727, 2, 28491, 2, 2, 2, 2, 2, 2, 2, 24671, 2, 2, 2, 20316, 2, 2, 2, 2, 17396, 2, 2, 2, 2, 2, 40, 2, 2, 2, 10279, 2, 2, 2, 2, 2, 89, 2, 2, 2, 11366, 2, 2, 2, 19587, 2, 2, 9232, 4920, 2, 2, 2, 2, 6890, 2, 2, 2, 2, 2, 2, 6701, 2, 2, 16948, 2, 2, 29117, 32, 9, 11535, 2, 2, 10169, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 15548, 20243, 14910, 2, 6559, 2, 7602, 2, 2, 2, 2, 2, 2, 2, 24549, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5236, 2, 2, 10467, 2, 2, 2, 2, 1271, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 24318, 9414, 14884, 2, 2, 2, 122, 2, 2, 2, 2, 12437, 2, 2, 3313, 2, 11599, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 51, 2, 2, 30830, 2, 2, 2, 28921, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9423, 15324, 2, 2, 2, 75, 2, 2, 2, 2, 102, 2, 2, 172, 226, 2, 2, 2, 2, 3198, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 17079, 2, 2, 2, 8497, 2, 19984, 2, 2, 2, 26731, 2, 10041, 13125, 2, 2, 2, 2, 2, 2, 2, 2, 15, 2, 2, 2, 2, 2, 13192, 2, 2, 2, 2, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 11968, 2, 2, 2, 2, 2, 2, 2, 20517, 2, 2, 2, 2, 14662, 2, 2, 2, 2, 2, 2, 2, 2, 16588, 2, 2, 2, 210, 715, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 22170, 2, 2, 2, 1408, 2, 157, 2, 2, 2, 2, 2, 2, 2, 2, 2, 52, 2, 2, 2, 2, 2, 2, 23, 2, 2, 2, 2, 2, 2, 8377, 2, 2, 6334, 115, 2, 8809, 14836, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2037, 31866, 2, 2, 2, 2, 2, 2, 2, 31247, 76, 2, 2, 2, 2, 2, 14492, 2, 12425, 2, 2, 2, 9988, 2, 2, 17504, 2, 30210, 2, 2, 2, 2, 208, 2, 2, 2, 2, 21182, 2, 2, 2, 2, 9955, 2, 2, 2, 2, 11956, 2, 2, 2, 2, 2, 2, 2, 25751, 2, 2, 2, 2, 3552, 2, 2, 2, 2, 2, 2, 2, 2, 17415, 17773, 14925, 354, 2, 2, 2, 2, 2, 27341, 2, 2, 2, 2, 2, 2, 2, 2, 17030, 2, 2, 2]\n",
      "INFO:__main__:Quantifier IDs: [2, 2]\n",
      "INFO:__main__:\n",
      "Processing NL Input: Every student loves some course.\n",
      "INFO:__main__:Input Text: Translate English to FOL: Every student loves some course.\n",
      "INFO:__main__:Generating beam outputs...\n",
      "INFO:__main__:Generated 1 beam hypotheses.\n",
      "INFO:__main__:Encoding generated FOL statements into hyperdimensional vectors...\n",
      "INFO:__main__:Calculating similarities with templatic references...\n",
      "INFO:__main__:Ranking completed.\n",
      "INFO:__main__:\n",
      "Processing NL Input: No teacher dislikes any subject.\n",
      "INFO:__main__:Input Text: Translate English to FOL: No teacher dislikes any subject.\n",
      "INFO:__main__:Generating beam outputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "NL Input: Every student loves some course.\n",
      "Standard Decoding FOL: ∀x (Student(x) → LovesCourses(x))\n",
      "Constrained Decoding FOL: ∀x (Student(x) → LovesCourses(x))\n",
      "Hyperdimensional Ranking FOL: ∀x (Student(x) → LovesCourses(x))\n",
      "All Beam Hypotheses and Similarities:\n",
      "Similarity: 0.9291, FOL: ∀x (Student(x) → LovesCourses(x))\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generated 1 beam hypotheses.\n",
      "INFO:__main__:Encoding generated FOL statements into hyperdimensional vectors...\n",
      "INFO:__main__:Calculating similarities with templatic references...\n",
      "INFO:__main__:Ranking completed.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Some professor teaches all classes.\n",
      "INFO:__main__:Input Text: Translate English to FOL: Some professor teaches all classes.\n",
      "INFO:__main__:Generating beam outputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "NL Input: No teacher dislikes any subject.\n",
      "Standard Decoding FOL: ∀x (Teacher(x) → ¬DislikesSubject(x))\n",
      "Constrained Decoding FOL: ∀x (Teacher(x) → ¬DislikesSubject(x))\n",
      "Hyperdimensional Ranking FOL: ∀x (Teacher(x) → ¬DislikesSubject(x))\n",
      "All Beam Hypotheses and Similarities:\n",
      "Similarity: 0.9282, FOL: ∀x (Teacher(x) → ¬DislikesSubject(x))\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generated 1 beam hypotheses.\n",
      "INFO:__main__:Encoding generated FOL statements into hyperdimensional vectors...\n",
      "INFO:__main__:Calculating similarities with templatic references...\n",
      "INFO:__main__:Ranking completed.\n",
      "INFO:__main__:\n",
      "Processing NL Input: All humans are mortal.\n",
      "INFO:__main__:Input Text: Translate English to FOL: All humans are mortal.\n",
      "INFO:__main__:Generating beam outputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "NL Input: Some professor teaches all classes.\n",
      "Standard Decoding FOL: ∃x (Professor(x) ∧ TeachesClasses(x))\n",
      "Constrained Decoding FOL: ∃x (Professor(x) ∧ TeachesClasses(x))\n",
      "Hyperdimensional Ranking FOL: ∃x (Professor(x) ∧ TeachesClasses(x))\n",
      "All Beam Hypotheses and Similarities:\n",
      "Similarity: 0.9269, FOL: ∃x (Professor(x) ∧ TeachesClasses(x))\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generated 1 beam hypotheses.\n",
      "INFO:__main__:Encoding generated FOL statements into hyperdimensional vectors...\n",
      "INFO:__main__:Calculating similarities with templatic references...\n",
      "INFO:__main__:Ranking completed.\n",
      "INFO:__main__:\n",
      "Processing NL Input: There exists a student who aces every test.\n",
      "INFO:__main__:Input Text: Translate English to FOL: There exists a student who aces every test.\n",
      "INFO:__main__:Generating beam outputs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "NL Input: All humans are mortal.\n",
      "Standard Decoding FOL: ∀x (Human(x) → Mortal(x))\n",
      "Constrained Decoding FOL: ∀x (Human(x) → Mortal(x))\n",
      "Hyperdimensional Ranking FOL: ∀x (Human(x) → Mortal(x))\n",
      "All Beam Hypotheses and Similarities:\n",
      "Similarity: 0.9314, FOL: ∀x (Human(x) → Mortal(x))\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generated 1 beam hypotheses.\n",
      "INFO:__main__:Encoding generated FOL statements into hyperdimensional vectors...\n",
      "INFO:__main__:Calculating similarities with templatic references...\n",
      "INFO:__main__:Ranking completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "NL Input: There exists a student who aces every test.\n",
      "Standard Decoding FOL: ∃x (Student(x) ∧ AcesTest(x))\n",
      "Constrained Decoding FOL: ∃x (Student(x) ∧ AcesTest(x))\n",
      "Hyperdimensional Ranking FOL: ∃x (Student(x) ∧ AcesTest(x))\n",
      "All Beam Hypotheses and Similarities:\n",
      "Similarity: 0.9255, FOL: ∃x (Student(x) ∧ AcesTest(x))\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# ranking with hyperdimensional embeddings\n",
    "\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.generation.logits_process import LogitsProcessor, LogitsProcessorList\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_REPO = \"snewmanaa/flan-t5-NL-FOL-baseline\"\n",
    "MAX_LENGTH = 128\n",
    "EMBEDDING_DIM = 1024\n",
    "BEAM_SIZE = 5\n",
    "\n",
    "SYMBOL_TO_PLACEHOLDER = {\n",
    "    \"∀\": \"[forall]\",\n",
    "    \"∃\": \"[exists]\",\n",
    "    \"¬\": \"[not]\",\n",
    "    \"→\": \"[implies]\",\n",
    "    \"∧\": \"[and]\",\n",
    "    \"∨\": \"[or]\",\n",
    "    \"⊕\": \"[oplus]\",\n",
    "    \"↔\": \"[iff]\",\n",
    "}\n",
    "\n",
    "PLACEHOLDER_TO_SYMBOL = {v: k for k, v in SYMBOL_TO_PLACEHOLDER.items()}\n",
    "\n",
    "def load_embeddings(symbol_embeddings_path=\"hyperdimensional_embeddings/symbol_embeddings.npy\",\n",
    "                   type_embeddings_path=\"hyperdimensional_embeddings/type_embeddings.npy\"):\n",
    "    \"\"\"\n",
    "    Load hyperdimensional embeddings from .npy files from step 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        symbol_embeddings = np.load(symbol_embeddings_path, allow_pickle=True).item()\n",
    "        type_embeddings = np.load(type_embeddings_path, allow_pickle=True).item()\n",
    "        logger.info(\"Loaded hyperdimensional embeddings successfully.\")\n",
    "        return symbol_embeddings, type_embeddings\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading embeddings: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def load_variables(file_path=\"hyperdimensional_embeddings/variables.txt\"):\n",
    "    \"\"\"\n",
    "    Load variables list from the text file saved in step 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            variables = [line.strip() for line in f.readlines()]\n",
    "        logger.info(f\"Loaded {len(variables)} variables from '{file_path}'.\")\n",
    "        return variables\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading variables from '{file_path}': {e}\")\n",
    "        return []\n",
    "\n",
    "def postprocess(decoded_texts):\n",
    "    \"\"\"\n",
    "    Replace placeholders with original symbols\n",
    "    \"\"\"\n",
    "    restored_texts = []\n",
    "    for text in decoded_texts:\n",
    "        for ph, sym in PLACEHOLDER_TO_SYMBOL.items():\n",
    "            text = text.replace(ph, sym)\n",
    "        restored_texts.append(text)\n",
    "    return restored_texts\n",
    "\n",
    "def encode_fol(fol, symbol_embeddings, type_embeddings):\n",
    "    \"\"\"\n",
    "    Encode a FOL string into a hyperdimensional vector\n",
    "    \"\"\"\n",
    "    tokens = fol.replace('(', ' ').replace(')', ' ').replace(',', ' ').split()\n",
    "    encoded = np.zeros(EMBEDDING_DIM)\n",
    "    for token in tokens:\n",
    "        if token in symbol_embeddings:\n",
    "            symbol_vec = symbol_embeddings[token]\n",
    "            if token in ['[forall]', '[exists]']:\n",
    "                type_vec = type_embeddings['quantifier']\n",
    "            elif token in ['[not]', '[implies]', '[and]', '[or]']:\n",
    "                type_vec = type_embeddings['operator']\n",
    "            elif token.islower():\n",
    "                type_vec = type_embeddings['variable']\n",
    "            elif token.isupper():\n",
    "                type_vec = type_embeddings['predicate']\n",
    "            else:\n",
    "                type_vec = type_embeddings['constant']\n",
    "            # Combine symbol and type vectors\n",
    "            combined = symbol_vec * type_vec\n",
    "            encoded += combined\n",
    "    return encoded\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return -1  # Minimal similarity\n",
    "    return np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(MODEL_REPO)\n",
    "        model = T5ForConditionalGeneration.from_pretrained(MODEL_REPO)\n",
    "        logger.info(f\"Loaded model '{MODEL_REPO}' successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model '{MODEL_REPO}': {e}\")\n",
    "        return\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    logger.info(f\"Model moved to {device}.\")\n",
    "\n",
    "    # Load hyperdimensional embeddings\n",
    "    symbol_embeddings, type_embeddings = load_embeddings()\n",
    "    if symbol_embeddings is None or type_embeddings is None:\n",
    "        logger.error(\"Failed to load embeddings. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Load variables\n",
    "    variables = load_variables()\n",
    "    if not variables:\n",
    "        logger.error(\"No variables loaded. Exiting.\")\n",
    "        return\n",
    "\n",
    "    variable_ids = tokenizer.convert_tokens_to_ids(variables)\n",
    "    logger.debug(f\"Variable IDs: {variable_ids}\")\n",
    "\n",
    "    quantifiers = [\"[forall]\", \"[exists]\"]\n",
    "    quantifier_ids = tokenizer.convert_tokens_to_ids(quantifiers)\n",
    "    logger.debug(f\"Quantifier IDs: {quantifier_ids}\")\n",
    "\n",
    "    #---EXAMPLES---#\n",
    "    test_cases = [\n",
    "        \"Every student loves some course.\",\n",
    "        \"No teacher dislikes any subject.\",\n",
    "        \"Some professor teaches all classes.\",\n",
    "        \"All humans are mortal.\",\n",
    "        \"There exists a student who aces every test.\"\n",
    "    ]\n",
    "\n",
    "    for nl_sentence in test_cases:\n",
    "        logger.info(f\"\\nProcessing NL Input: {nl_sentence}\")\n",
    "        input_text = \"Translate English to FOL: \" + nl_sentence\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "        logger.info(f\"Input Text: {input_text}\")\n",
    "\n",
    "        logger.info(\"Generating beam outputs...\")\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    max_length=MAX_LENGTH,\n",
    "                    num_beams=BEAM_SIZE,\n",
    "                    early_stopping=False,  # For beam search\n",
    "                    return_dict_in_generate=True,\n",
    "                    output_scores=False,\n",
    "                    output_hidden_states=False\n",
    "                )\n",
    "            beam_outputs = outputs.sequences\n",
    "            decoded_outputs = tokenizer.batch_decode(beam_outputs, skip_special_tokens=True)\n",
    "            decoded_outputs = postprocess(decoded_outputs)\n",
    "            logger.info(f\"Generated {len(decoded_outputs)} beam hypotheses.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during generation: {e}\")\n",
    "            continue\n",
    "\n",
    "        logger.info(\"Encoding generated FOL statements into hyperdimensional vectors...\")\n",
    "        encoded_generated = [encode_fol(fol, symbol_embeddings, type_embeddings) \n",
    "                             for fol in decoded_outputs]\n",
    "\n",
    "        templates = [\n",
    "                \"∀x (Predicate(x) → Predicate(x))\",\n",
    "                \"∃x (Predicate(x) ∧ Predicate(x))\",\n",
    "                \"∀x (Predicate(x) ↔ Predicate(x))\",\n",
    "                \"∃x (Predicate(x) → Predicate(x))\",\n",
    "                \"∀x ∃y (Predicate(x, y))\",\n",
    "                \"∀x (Predicate1(x) → ∃y Predicate2(y))\",\n",
    "                \"∃x ∀y (Predicate(x) → Predicate(y))\",\n",
    "                \"∀x (Predicate(x) ∨ Predicate(x))\",\n",
    "                \"∃x (¬Predicate(x))\",\n",
    "                \"∀x ∀y (Predicate(x, y) → Predicate(y, x))\",\n",
    "                \"∀x ∃y (Predicate1(x) ∧ Predicate2(y))\",\n",
    "                \"∃x ∃y (Predicate1(x) ∨ Predicate2(y))\",\n",
    "                \"∀x (¬Predicate(x))\",\n",
    "                \"∃x (Predicate(x) → ∃y Predicate(y))\",\n",
    "                \"∀x ∀y ∃z (Predicate(x, y, z))\"\n",
    "            ]\n",
    "\n",
    "        reference_embeddings = [encode_fol(template, symbol_embeddings, type_embeddings) for template in templates]\n",
    "\n",
    "        # Compute similarity of each hypothesis with all templates and select\n",
    "        # the hypothesis with the highest similarity\n",
    "        logger.info(\"Calculating similarities with templatic references...\")\n",
    "        best_similarity = -1\n",
    "        best_fol = None\n",
    "        for fol, gen_vec in zip(decoded_outputs, encoded_generated):\n",
    "            sims = [cosine_similarity(gen_vec, ref_vec) for ref_vec in reference_embeddings]\n",
    "            max_sim = max(sims)\n",
    "            if max_sim > best_similarity:\n",
    "                best_similarity = max_sim\n",
    "                best_fol = fol\n",
    "\n",
    "        logger.info(\"Ranking completed.\")\n",
    "\n",
    "        print(\"\\n---\")\n",
    "        print(f\"NL Input: {nl_sentence}\")\n",
    "        print(f\"Standard Decoding FOL: {decoded_outputs[0]}\")\n",
    "        print(f\"Constrained Decoding FOL: {decoded_outputs[0]}\")\n",
    "        print(f\"Hyperdimensional Ranking FOL: {best_fol}\")\n",
    "        print(\"All Beam Hypotheses and Similarities:\")\n",
    "        for fol, gen_vec in zip(decoded_outputs, encoded_generated):\n",
    "            sims = [cosine_similarity(gen_vec, ref_vec) for ref_vec in reference_embeddings]\n",
    "            max_sim = max(sims)\n",
    "            print(f\"Similarity: {max_sim:.4f}, FOL: {fol}\")\n",
    "        print(\"---\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "W_S6yCxIkrQ9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.generation.logits_process import LogitsProcessor, LogitsProcessorList\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "def compare_methods(subset_size=None, subset_fraction=None, num_qualitative=5):\n",
    "    \"\"\"\n",
    "    Compare different decoding methods for NL to FOL translation.\n",
    "\n",
    "    Parameters:\n",
    "    - subset_size (int): Number of test examples to evaluate.\n",
    "    - subset_fraction (float): Fraction of test examples to evaluate (e.g., 0.1 for 10%).\n",
    "    - num_qualitative (int): Number of examples to log for qualitative analysis.\n",
    "    \"\"\"\n",
    "    # Configuration constants\n",
    "    MODEL_REPO = \"snewmanaa/flan-t5-NL-FOL-baseline\"\n",
    "    MAX_LENGTH = 128\n",
    "    EMBEDDING_DIM = 1024\n",
    "    BEAM_SIZE = 5\n",
    "    TEST_SPLIT = \"test\"\n",
    "\n",
    "    SYMBOL_TO_PLACEHOLDER = {\n",
    "        \"∀\": \"[forall]\",\n",
    "        \"∃\": \"[exists]\",\n",
    "        \"¬\": \"[not]\",\n",
    "        \"→\": \"[implies]\",\n",
    "        \"∧\": \"[and]\",\n",
    "        \"∨\": \"[or]\",\n",
    "        \"⊕\": \"[oplus]\",\n",
    "        \"↔\": \"[iff]\",\n",
    "    }\n",
    "\n",
    "    PLACEHOLDER_TO_SYMBOL = {v: k for k, v in SYMBOL_TO_PLACEHOLDER.items()}\n",
    "\n",
    "    def load_embeddings(symbol_embeddings_path=\"hyperdimensional_embeddings/symbol_embeddings.npy\",\n",
    "                       type_embeddings_path=\"hyperdimensional_embeddings/type_embeddings.npy\"):\n",
    "        \"\"\"\n",
    "        Load hyperdimensional embeddings from .npy files.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            symbol_embeddings = np.load(symbol_embeddings_path, allow_pickle=True).item()\n",
    "            type_embeddings = np.load(type_embeddings_path, allow_pickle=True).item()\n",
    "            logger.info(\"Loaded hyperdimensional embeddings successfully.\")\n",
    "            return symbol_embeddings, type_embeddings\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading embeddings: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def load_variables(file_path=\"hyperdimensional_embeddings/variables.txt\"):\n",
    "        \"\"\"\n",
    "        Load variables list from a text file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_path, \"r\") as f:\n",
    "                variables = [line.strip() for line in f.readlines()]\n",
    "            logger.info(f\"Loaded {len(variables)} variables from '{file_path}'.\")\n",
    "            return variables\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading variables from '{file_path}': {e}\")\n",
    "            return []\n",
    "\n",
    "    def load_test_set(dataset_name=\"yuan-yang/MALLS-v0\", split=TEST_SPLIT, \n",
    "                      subset_size=None, subset_fraction=None):\n",
    "        \"\"\"\n",
    "        Load the test set from the dataset, optionally loading a subset (for time)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dataset = load_dataset(dataset_name, split=split)\n",
    "            logger.info(f\"Loaded test set '{split}' with {len(dataset)} examples.\")\n",
    "\n",
    "            if subset_size:\n",
    "                subset_size = min(subset_size, len(dataset))\n",
    "                dataset = dataset.select(range(subset_size))\n",
    "                logger.info(f\"Selected subset of size {subset_size} for evaluation.\")\n",
    "            elif subset_fraction:\n",
    "                subset_size = int(len(dataset) * subset_fraction)\n",
    "                subset_size = min(subset_size, len(dataset))\n",
    "                dataset = dataset.select(range(subset_size))\n",
    "                logger.info(f\"Selected subset of size {subset_size} ({subset_fraction*100}%) for evaluation.\")\n",
    "\n",
    "            return dataset\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading test set '{split}': {e}\")\n",
    "            return None\n",
    "\n",
    "    def postprocess(decoded_texts):\n",
    "        \"\"\"\n",
    "        Replace placeholders with original symbols\n",
    "        \"\"\"\n",
    "        restored_texts = []\n",
    "        for text in decoded_texts:\n",
    "            for ph, sym in PLACEHOLDER_TO_SYMBOL.items():\n",
    "                text = text.replace(ph, sym)\n",
    "            restored_texts.append(text)\n",
    "        return restored_texts\n",
    "\n",
    "    def encode_fol(fol, symbol_embeddings, type_embeddings):\n",
    "        \"\"\"\n",
    "        Encode a FOL string into a hyperdimensional vector\n",
    "        \"\"\"\n",
    "        tokens = fol.replace('(', ' ').replace(')', ' ').replace(',', ' ').split()\n",
    "        encoded = np.zeros(EMBEDDING_DIM)\n",
    "        for token in tokens:\n",
    "            if token in symbol_embeddings:\n",
    "                symbol_vec = symbol_embeddings[token]\n",
    "                if token in ['[forall]', '[exists]']:\n",
    "                    type_vec = type_embeddings.get('quantifier', np.zeros(EMBEDDING_DIM))\n",
    "                elif token in ['[not]', '[implies]', '[and]', '[or]']:\n",
    "                    type_vec = type_embeddings.get('operator', np.zeros(EMBEDDING_DIM))\n",
    "                elif token.islower():\n",
    "                    type_vec = type_embeddings.get('variable', np.zeros(EMBEDDING_DIM))\n",
    "                elif token.isupper():\n",
    "                    type_vec = type_embeddings.get('predicate', np.zeros(EMBEDDING_DIM))\n",
    "                else:\n",
    "                    type_vec = type_embeddings.get('constant', np.zeros(EMBEDDING_DIM))\n",
    "                # Combine symbol and type vectors\n",
    "                combined = symbol_vec * type_vec\n",
    "                encoded += combined\n",
    "        return encoded\n",
    "\n",
    "    def cosine_similarity(vec1, vec2):\n",
    "        \"\"\"\n",
    "        Compute cosine similarity between two vectors\n",
    "        \"\"\"\n",
    "        norm1 = np.linalg.norm(vec1)\n",
    "        norm2 = np.linalg.norm(vec2)\n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            return -1  # Minimal similarity\n",
    "        return np.dot(vec1, vec2) / (norm1 * norm2)\n",
    "\n",
    "    def calculate_metrics(gold, predictions):\n",
    "        \"\"\"\n",
    "        Calculate evaluation metrics\n",
    "        \"\"\"\n",
    "        # Filter out any None or empty string predictions\n",
    "        filtered_gold = []\n",
    "        filtered_preds = []\n",
    "        for g, p in zip(gold, predictions):\n",
    "            if p:\n",
    "                filtered_gold.append(g)\n",
    "                filtered_preds.append(p)\n",
    "\n",
    "        if not filtered_gold:\n",
    "            logger.warning(\"No valid predictions to calculate metrics.\")\n",
    "            return 0.0, 0.0, 0.0, []\n",
    "\n",
    "        # Exact Match\n",
    "        exact_matches = [1 if g == p else 0 for g, p in zip(filtered_gold, filtered_preds)]\n",
    "        accuracy = accuracy_score(filtered_gold, filtered_preds)\n",
    "\n",
    "        # BLEU Score\n",
    "        smoothie = SmoothingFunction().method4\n",
    "        bleu_scores = [sentence_bleu([g.split()], p.split(), smoothing_function=smoothie) \n",
    "                       for g, p in zip(filtered_gold, filtered_preds)]\n",
    "        avg_bleu = np.mean(bleu_scores)\n",
    "\n",
    "        return accuracy, avg_bleu, exact_matches\n",
    "\n",
    "    class QuantifierFollowProcessor(LogitsProcessor):\n",
    "        \"\"\"\n",
    "        Custom LogitsProcessor to enforce that quantifiers are followed by variables\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, quantifier_ids, variable_ids, device):\n",
    "            super().__init__()\n",
    "            self.quantifier_ids = quantifier_ids\n",
    "            self.variable_ids = variable_ids\n",
    "            self.device = device\n",
    "\n",
    "        def __call__(self, input_ids, scores):\n",
    "            # Get the last generated token for each sequence in the batch\n",
    "            last_token_ids = input_ids[:, -1]\n",
    "\n",
    "            # Create a mask where the last token is a quantifier\n",
    "            is_quantifier = torch.zeros_like(last_token_ids, dtype=torch.bool)\n",
    "            for q_id in self.quantifier_ids:\n",
    "                is_quantifier = is_quantifier | (last_token_ids == q_id)\n",
    "\n",
    "            # For each sequence where the last token is a quantifier,\n",
    "            # set all logits to -inf except for variable_ids\n",
    "            for i, flag in enumerate(is_quantifier):\n",
    "                if flag:\n",
    "                    # Set all logits to -inf\n",
    "                    scores[i] = torch.full_like(scores[i], -float(\"inf\"))\n",
    "                    # Allow only variable_ids by setting their logits to 0\n",
    "                    scores[i, self.variable_ids] = 0.0\n",
    "\n",
    "            return scores\n",
    "\n",
    "    def standard_decoding(model, tokenizer, input_ids):\n",
    "        \"\"\"\n",
    "        Standard decoding without constraints or ranking\n",
    "        \"\"\"\n",
    "        logger.debug(\"Performing standard decoding...\")\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                output_ids = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    max_length=MAX_LENGTH,\n",
    "                    num_beams=BEAM_SIZE,\n",
    "                    early_stopping=True,\n",
    "                    return_dict_in_generate=False,\n",
    "                    output_scores=False,\n",
    "                    output_hidden_states=False\n",
    "                )\n",
    "            decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "            final_output = postprocess([decoded])[0]\n",
    "            logger.debug(f\"Standard Decoding FOL: {final_output}\")\n",
    "            return final_output\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during standard decoding: {e}\")\n",
    "            return \"\"  # Return empty string instead of None\n",
    "\n",
    "    def constrained_decoding(model, tokenizer, input_ids, quantifier_ids, \n",
    "                             variable_ids, device):\n",
    "        \"\"\"\n",
    "        Decoding with rule-based constraints\n",
    "        \"\"\"\n",
    "        logger.debug(\"Performing constrained decoding...\")\n",
    "        try:\n",
    "            # Initialize custom logits processor\n",
    "            custom_processor = QuantifierFollowProcessor(quantifier_ids, variable_ids, device)\n",
    "            custom_processors = LogitsProcessorList([custom_processor])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_ids = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    max_length=MAX_LENGTH,\n",
    "                    num_beams=BEAM_SIZE,\n",
    "                    logits_processor=custom_processors,\n",
    "                    early_stopping=True,\n",
    "                    return_dict_in_generate=False,\n",
    "                    output_scores=False,\n",
    "                    output_hidden_states=False\n",
    "                )\n",
    "            decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "            final_output = postprocess([decoded])[0]\n",
    "            logger.debug(f\"Constrained Decoding FOL: {final_output}\")\n",
    "            return final_output\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during constrained decoding: {e}\")\n",
    "            return \"\"  # Return empty string instead of None\n",
    "\n",
    "    def hyperdimensional_ranking_decoding(model, tokenizer, input_ids, \n",
    "                                          symbol_embeddings, type_embeddings, \n",
    "                                          print_beams=False, nl_sentence=\"\", \n",
    "                                          gold_fol=\"\"):\n",
    "        \"\"\"\n",
    "        Decoding with hyperdimensional embeddings ranking using templatic references.\n",
    "        Optionally print beam hypotheses and similarities\n",
    "        \"\"\"\n",
    "        logger.debug(\"Performing hyperdimensional embedding ranking decoding...\")\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    max_length=MAX_LENGTH,\n",
    "                    num_beams=BEAM_SIZE,\n",
    "                    early_stopping=False,  # Allow beam search to explore all beams\n",
    "                    return_dict_in_generate=True,\n",
    "                    output_scores=False,\n",
    "                    output_hidden_states=False,\n",
    "                    num_return_sequences=BEAM_SIZE  # All beam hypotheses are returned\n",
    "                )\n",
    "            beam_outputs = outputs.sequences\n",
    "            decoded_outputs = tokenizer.batch_decode(beam_outputs, skip_special_tokens=True)\n",
    "            decoded_outputs = postprocess(decoded_outputs)\n",
    "            logger.debug(f\"Generated {len(decoded_outputs)} beam hypotheses\")\n",
    "\n",
    "            # Encode the generated FOL statements\n",
    "            logger.debug(\"Encoding generated FOL statements into hyperdimensional vectors...\")\n",
    "            encoded_generated = [encode_fol(fol, symbol_embeddings, type_embeddings) for fol in decoded_outputs]\n",
    "\n",
    "            # Define templatic reference encodings\n",
    "            templates = [\n",
    "                \"∀x (Predicate(x) → Predicate(x))\",\n",
    "                \"∃x (Predicate(x) ∧ Predicate(x))\",\n",
    "                \"∀x (Predicate(x) ↔ Predicate(x))\",\n",
    "                \"∃x (Predicate(x) → Predicate(x))\",\n",
    "                \"∀x ∃y (Predicate(x, y))\",\n",
    "                \"∀x (Predicate1(x) → ∃y Predicate2(y))\",\n",
    "                \"∃x ∀y (Predicate(x) → Predicate(y))\",\n",
    "                \"∀x (Predicate(x) ∨ Predicate(x))\",\n",
    "                \"∃x (¬Predicate(x))\",\n",
    "                \"∀x ∀y (Predicate(x, y) → Predicate(y, x))\",\n",
    "                \"∀x ∃y (Predicate1(x) ∧ Predicate2(y))\",\n",
    "                \"∃x ∃y (Predicate1(x) ∨ Predicate2(y))\",\n",
    "                \"∀x (¬Predicate(x))\",\n",
    "                \"∃x (Predicate(x) → ∃y Predicate(y))\",\n",
    "                \"∀x ∀y ∃z (Predicate(x, y, z))\"\n",
    "            ]\n",
    "            reference_embeddings = [encode_fol(template, symbol_embeddings, type_embeddings) for template in templates]\n",
    "\n",
    "            # Compute similarity of each hypothesis with all templates and select the highest\n",
    "            logger.debug(\"Calculating similarities with templatic references...\")\n",
    "            best_similarity = -1\n",
    "            best_fol = \"\"\n",
    "            for fol, gen_vec in zip(decoded_outputs, encoded_generated):\n",
    "                # Compute similarity with each template and take the maximum\n",
    "                sims = [cosine_similarity(gen_vec, ref_vec) for ref_vec in reference_embeddings]\n",
    "                max_sim = max(sims)\n",
    "                if max_sim > best_similarity:\n",
    "                    best_similarity = max_sim\n",
    "                    best_fol = fol\n",
    "\n",
    "            logger.debug(\"Ranking completed\")\n",
    "\n",
    "            # Display ranked hypotheses only if requested\n",
    "            if print_beams:\n",
    "                print(\"\\n--- Qualitative Analysis ---\")\n",
    "                print(f\"Reference NL: {nl_sentence}\")\n",
    "                print(f\"Gold FOL: {gold_fol}\")\n",
    "                print(f\"Hyperdimensional Ranking FOL: {best_fol}\")\n",
    "                print(\"All Beam Hypotheses and Similarities:\")\n",
    "                for fol, gen_vec in zip(decoded_outputs, encoded_generated):\n",
    "                    # Compute similarity with each template and take the maximum\n",
    "                    sims = [cosine_similarity(gen_vec, ref_vec) for ref_vec in reference_embeddings]\n",
    "                    max_sim = max(sims)\n",
    "                    print(f\"Similarity: {max_sim:.4f}, FOL: {fol}\")\n",
    "                print(\"---\\n\")\n",
    "\n",
    "            return best_fol\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during hyperdimensional embedding ranking decoding: {e}\")\n",
    "            return \"\"  # Return empty string instead of None\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    try:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(MODEL_REPO)\n",
    "        model = T5ForConditionalGeneration.from_pretrained(MODEL_REPO)\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        model.to(device)\n",
    "        logger.info(f\"Loaded model and moved to {device}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    # Load hyperdimensional embeddings\n",
    "    symbol_embeddings, type_embeddings = load_embeddings()\n",
    "    if symbol_embeddings is None or type_embeddings is None:\n",
    "        logger.error(\"Failed to load embeddings. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Load variables\n",
    "    variables = load_variables()\n",
    "    if not variables:\n",
    "        logger.error(\"No variables loaded. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Convert variables to IDs\n",
    "    variable_ids = tokenizer.convert_tokens_to_ids(variables)\n",
    "    logger.info(f\"Variable IDs: {variable_ids}\")\n",
    "\n",
    "    # Define quantifier tokens\n",
    "    quantifiers = [\"[forall]\", \"[exists]\"]\n",
    "    quantifier_ids = tokenizer.convert_tokens_to_ids(quantifiers)\n",
    "    logger.info(f\"Quantifier IDs: {quantifier_ids}\")\n",
    "\n",
    "    # Load test set with optional subset\n",
    "    test_set = load_test_set(subset_size=subset_size, subset_fraction=subset_fraction)\n",
    "    if test_set is None:\n",
    "        logger.error(\"No test set loaded. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Initialize lists for metrics\n",
    "    gold_fols = []\n",
    "    standard_preds = []\n",
    "    constrained_preds = []\n",
    "    ranked_preds = []\n",
    "\n",
    "    # Select unique random examples for qualitative analysis\n",
    "    total_examples = len(test_set)\n",
    "    num_random = min(num_qualitative, total_examples)\n",
    "    if total_examples < num_qualitative:\n",
    "        logger.warning(f\"Test set contains only {total_examples} examples.\")\n",
    "        num_random = total_examples\n",
    "    random_examples = set(random.sample(range(total_examples), num_random))\n",
    "\n",
    "    for idx, example in enumerate(test_set):\n",
    "        nl_sentence = example.get('NL', '')\n",
    "        gold_fol = example.get('FOL', '')\n",
    "\n",
    "        if not isinstance(nl_sentence, str) or not isinstance(gold_fol, str):\n",
    "            logger.warning(f\"Missing or invalid NL or FOL at index {idx}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        input_text = \"Translate English to FOL: \" + nl_sentence\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "        logger.info(f\"\\nProcessing NL Input: {nl_sentence}\")\n",
    "\n",
    "        # Standard Decoding\n",
    "        standard_fol = standard_decoding(model, tokenizer, input_ids, device)\n",
    "        standard_preds.append(standard_fol if standard_fol else \"\")\n",
    "        gold_fols.append(gold_fol)\n",
    "\n",
    "        # Constrained Decoding\n",
    "        constrained_fol = constrained_decoding(model, tokenizer, input_ids, quantifier_ids, variable_ids, device)\n",
    "        constrained_preds.append(constrained_fol if constrained_fol else \"\")\n",
    "\n",
    "        # Hyperdimensional Embedding Ranking Decoding\n",
    "        # Print beams only for selected random examples\n",
    "        print_beams = idx in random_examples\n",
    "        ranked_fol = hyperdimensional_ranking_decoding(\n",
    "            model, tokenizer, input_ids, symbol_embeddings, type_embeddings, device,\n",
    "            print_beams=print_beams,\n",
    "            nl_sentence=nl_sentence,\n",
    "            gold_fol=gold_fol\n",
    "        )\n",
    "        ranked_preds.append(ranked_fol if ranked_fol else \"\")\n",
    "\n",
    "    # Calculate Metrics\n",
    "    logger.info(\"Calculating evaluation metrics...\")\n",
    "    accuracy_std, avg_bleu_std, exact_matches_std = calculate_metrics(gold_fols, standard_preds)\n",
    "    accuracy_constrained, avg_bleu_constrained, exact_matches_constrained = calculate_metrics(gold_fols, constrained_preds)\n",
    "    accuracy_ranked, avg_bleu_ranked, exact_matches_ranked = calculate_metrics(gold_fols, ranked_preds)\n",
    "\n",
    "    # Print Metrics\n",
    "    print(\"\\n=== Evaluation Metrics ===\")\n",
    "    print(f\"Standard Decoding - Accuracy: {accuracy_std:.4f}, Avg BLEU: {avg_bleu_std:.4f}\")\n",
    "    print(f\"Constrained Decoding - Accuracy: {accuracy_constrained:.4f}, Avg BLEU: {avg_bleu_constrained:.4f}\")\n",
    "    print(f\"Hyperdimensional Ranking Decoding - Accuracy: {accuracy_ranked:.4f}, Avg BLEU: {avg_bleu_ranked:.4f}\")\n",
    "    print(\"==========================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbTtwBQ_LLx8",
    "outputId": "9ce2b55d-86d4-4336-d022-bf055b534522"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded model and moved to cuda.\n",
      "INFO:__main__:Loaded hyperdimensional embeddings successfully.\n",
      "INFO:__main__:Loaded 620 variables from 'hyperdimensional_embeddings/variables.txt'.\n",
      "INFO:__main__:Variable IDs: [2, 2, 2, 26, 4250, 7325, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 19747, 2, 2, 2, 22288, 2, 2, 2, 2, 2, 2, 2, 15974, 2, 107, 2, 2, 20779, 2, 2256, 2, 2, 20113, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3009, 2, 5842, 2, 2, 2, 2, 2, 2, 63, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1135, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 29, 2, 28188, 2, 2, 2, 2, 14700, 20309, 2, 2, 2, 2857, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7149, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5556, 2, 6075, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2242, 2, 2, 26809, 2, 2, 6633, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2138, 2, 2, 2, 2, 2, 5165, 2, 2, 2, 2, 8115, 2, 2, 2, 2, 2, 2, 2, 6779, 2, 2, 2, 2, 2, 2, 2, 2, 15727, 2, 28491, 2, 2, 2, 2, 2, 2, 2, 24671, 2, 2, 2, 20316, 2, 2, 2, 2, 17396, 2, 2, 2, 2, 2, 40, 2, 2, 2, 10279, 2, 2, 2, 2, 2, 89, 2, 2, 2, 11366, 2, 2, 2, 19587, 2, 2, 9232, 4920, 2, 2, 2, 2, 6890, 2, 2, 2, 2, 2, 2, 6701, 2, 2, 16948, 2, 2, 29117, 32, 9, 11535, 2, 2, 10169, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 15548, 20243, 14910, 2, 6559, 2, 7602, 2, 2, 2, 2, 2, 2, 2, 24549, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5236, 2, 2, 10467, 2, 2, 2, 2, 1271, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 24318, 9414, 14884, 2, 2, 2, 122, 2, 2, 2, 2, 12437, 2, 2, 3313, 2, 11599, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 51, 2, 2, 30830, 2, 2, 2, 28921, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9423, 15324, 2, 2, 2, 75, 2, 2, 2, 2, 102, 2, 2, 172, 226, 2, 2, 2, 2, 3198, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 17079, 2, 2, 2, 8497, 2, 19984, 2, 2, 2, 26731, 2, 10041, 13125, 2, 2, 2, 2, 2, 2, 2, 2, 15, 2, 2, 2, 2, 2, 13192, 2, 2, 2, 2, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 11968, 2, 2, 2, 2, 2, 2, 2, 20517, 2, 2, 2, 2, 14662, 2, 2, 2, 2, 2, 2, 2, 2, 16588, 2, 2, 2, 210, 715, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 22170, 2, 2, 2, 1408, 2, 157, 2, 2, 2, 2, 2, 2, 2, 2, 2, 52, 2, 2, 2, 2, 2, 2, 23, 2, 2, 2, 2, 2, 2, 8377, 2, 2, 6334, 115, 2, 8809, 14836, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2037, 31866, 2, 2, 2, 2, 2, 2, 2, 31247, 76, 2, 2, 2, 2, 2, 14492, 2, 12425, 2, 2, 2, 9988, 2, 2, 17504, 2, 30210, 2, 2, 2, 2, 208, 2, 2, 2, 2, 21182, 2, 2, 2, 2, 9955, 2, 2, 2, 2, 11956, 2, 2, 2, 2, 2, 2, 2, 25751, 2, 2, 2, 2, 3552, 2, 2, 2, 2, 2, 2, 2, 2, 17415, 17773, 14925, 354, 2, 2, 2, 2, 2, 27341, 2, 2, 2, 2, 2, 2, 2, 2, 17030, 2, 2, 2]\n",
      "INFO:__main__:Quantifier IDs: [2, 2]\n",
      "INFO:__main__:Loaded test set 'test' with 1000 examples.\n",
      "INFO:__main__:Selected subset of size 200 for evaluation.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vacation is relaxing if it includes beautiful scenery and enjoyable activities.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A gemstone can be a diamond, a ruby, or an emerald, but not more than one type of gemstone.\n",
      "INFO:__main__:\n",
      "Processing NL Input: People who speak more than one language are bilingual or multilingual.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An organization is non-profit if it has a charitable mission, does not distribute profits to owners, and primarily relies on donations.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A flower is characterized as a monocot if it has a single cotyledon, parallel-veined leaves, and flower parts in multiples of three.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A fabric that is lightweight, breathable, and absorbs moisture is suitable for athletic wear.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A place is considered a library if it houses a collection of books, periodicals, and other media for public use and study.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Birds possess feathers, have a beak, and lay eggs, while their ability to fly is facilitated by their lightweight bones and specialized muscles.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A child plays with a toy in a playground.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A person is considered a physicist if they study the nature and properties of matter and energy.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A well-insulated building conserves energy by maintaining a stable temperature.\n",
      "INFO:__main__:\n",
      "Processing NL Input: To be eligible for a promotion, an employee must have worked at the company for at least two years and have a good performance record, unless they have a recommendation from a supervisor.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Not all flowers bloom in spring.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A movie is classified as a romantic comedy if it has elements of both romance and comedy.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Chefs prepare meals, waiters serve meals, and customers enjoy meals at a restaurant.\n",
      "INFO:__main__:\n",
      "Processing NL Input: If a vehicle can travel on both land and water, it is an amphibious vehicle.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A tool with a long handle, a flat blade, and is used for lifting and moving loose material is a shovel.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A camera can capture photos or record videos.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A balanced diet that includes a variety of fruits, vegetables, and lean proteins can provide essential nutrients and promote overall health and wellness.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vehicle that is designed for traveling on snow, equipped with skis or tracks, and powered by an engine is a snowmobile.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A sports event could be played indoors or outdoors, not both.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A product is eco-friendly if it is made from sustainable materials, has a low carbon footprint, or encourages conservation of resources.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A tsunami can be triggered by underwater earthquakes, volcanic eruptions, or landslides, causing a series of massive waves that devastate coastal areas.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A device that uses electricity and emits light is a light-emitting device.\n",
      "INFO:__main__:\n",
      "Processing NL Input: If a person works in the news industry and reports on events, they are considered a journalist.\n",
      "INFO:__main__:\n",
      "Processing NL Input: All triangles with equal sides have equal angles.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Some bicycles are lightweight, durable, and suitable for off-road use.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A bird flies if it has wings.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A garment that is worn on the lower part of the body, has separate openings for each leg, and is made of fabric is a pair of pants or a skirt.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A polygon with three sides and three angles is a triangle.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A sport that is played between two teams on a field with a ball and the objective is to score points by getting the ball into the opposing team's goal is a goal-based sport.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An orchestra performs a concert with musicians playing various instruments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Qualitative Analysis ---\n",
      "Reference NL: A sport that is played between two teams on a field with a ball and the objective is to score points by getting the ball into the opposing team's goal is a goal-based sport.\n",
      "Gold FOL: ∀x (Sport(x) ∧ PlayedBetweenTwoTeams(x) ∧ PlayedOnField(x) ∧ PlayedWithBall(x) ∧ ObjectiveToScorePointsByGettingBallIntoOpposingTeamsGoal(x) → GoalBasedSport(x))\n",
      "Hyperdimensional Ranking FOL: ∀x (Sport(x) ∧ PlayedBetweenTwoTeams(x) ∧ FieldWithBall(x) ∧ ObjectiveIsToScorePoints(x) ∧ GetsBallIntoOpposingTeamGoal(x) → GoalBasedSport(x))\n",
      "All Beam Hypotheses and Similarities:\n",
      "Similarity: 0.8652, FOL: ∀x (Sport(x) ∧ PlayedBetweenTwoTeams(x) ∧ FieldWithBall(x) ∧ ObjectiveToScorePoints(x) ∧ GetsBallIntoOpposingTeamGoal(x) → GoalBasedSport(x))\n",
      "Similarity: 0.8736, FOL: ∀x (Sport(x) ∧ PlayedBetweenTwoTeams(x) ∧ FieldWithBall(x) ∧ ObjectiveIsToScorePoints(x) ∧ GetsBallIntoOpposingTeamGoal(x) → GoalBasedSport(x))\n",
      "Similarity: 0.8729, FOL: ∀x (Sport(x) ∧ PlayedBetweenTwoTeams(x) ∧ FieldWithBall(x) ∧ Objective(x) ∧ ScorePoints(x) ∧ GetsBallIntoOpposingTeamGoal(x) → GoalBasedSport(x))\n",
      "Similarity: 0.8655, FOL: ∀x (Sport(x) ∧ PlayedBetweenTwoTeams(x) ∧ FieldWithBall(x) ∧ Objective(x) ∧ ScorePointsByGivingBallIntoOpposingTeamGoal(x) → GoalBasedSport(x))\n",
      "Similarity: 0.8729, FOL: ∀x (Sport(x) ∧ PlayedBetweenTwoTeams(x) ∧ FieldWithBall(x) ∧ Objective(x) ∧ ScorePoints(x) ∧ GetBallIntoOpposingTeamGoal(x) → GoalBasedSport(x))\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Processing NL Input: A detective solves crimes by gathering evidence and analyzing clues.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Some paintings are abstract and created by famous artists.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An instrument is either a string instrument or a wind instrument, but not both.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Mammals give birth to live young and nurse their offspring with milk produced by the mother.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vaccine that is effective provides immunity, reduces the risk of infection, and often contributes to herd immunity in a population.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A satellite orbits Earth, transmitting and receiving data, enabling services such as weather forecasting, global positioning, and communication.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A flower blooms in spring if it requires a specific amount of sunlight and warmth for its growth and development.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A tree loses its leaves in the autumn, while an evergreen tree retains its leaves throughout the year.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A smartphone can be used for communication, entertainment, and productivity.\n",
      "INFO:__main__:\n",
      "Processing NL Input: When a bird migrates, it travels long distances, often across continents, and usually follows a seasonal pattern to find resources.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An electron can be found in either an orbital or a suborbital, but not in both simultaneously.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A coat is appropriate for cold weather if it is made of wool, has a hood, and is insulated.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A type of music that originated in African American communities, features improvisation, and uses syncopation is called jazz.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A country has a coastline if it is bordered by an ocean or a sea.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A prism disperses white light into a spectrum of colors.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A book becomes a bestseller when it has a high sales volume and positive reviews.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Farmers grow crops, while miners extract minerals.\n",
      "INFO:__main__:\n",
      "Processing NL Input: If an individual participates in community events, they are more likely to have a strong sense of belonging and connection with their community.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Winter is cold, and summer is hot.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A beverage that contains caffeine, is served hot, and is made from roasted seeds is coffee.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A planet with an atmosphere containing oxygen can support human life.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A building with proper insulation, energy-efficient windows, and solar panels is considered energy efficient.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A river flows from its source, often in the mountains, through various landscapes until it reaches a larger body of water, such as an ocean or lake.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A dessert is frozen if it requires refrigeration, is served cold, and isn't a baked good.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A clock measures time, and a scale measures weight.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A company that produces electronics and has a global presence is an international electronics manufacturer.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A building has either an elevator or stairs, but not both.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A computer requires an input device, such as a keyboard or a mouse, and an output device, like a monitor or speakers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Qualitative Analysis ---\n",
      "Reference NL: A building has either an elevator or stairs, but not both.\n",
      "Gold FOL: ∀x (Building(x) → ((HasElevator(x) ⊕ HasStairs(x))))\n",
      "Hyperdimensional Ranking FOL: ∀x (Building(x) → (HasElevator(x)  HasStoves(x)))\n",
      "All Beam Hypotheses and Similarities:\n",
      "Similarity: 0.8810, FOL: ∀x (Building(x) → (Elevator(x)  Stairs(x)))\n",
      "Similarity: 0.9075, FOL: ∀x (Building(x) → (HasElevator(x)  HasStoves(x)))\n",
      "Similarity: 0.8810, FOL: ∀x (Building(x) → ((Elevator(x)  Stairs(x))))\n",
      "Similarity: 0.9075, FOL: ∀x (Building(x) → ((HasElevator(x)  HasStoves(x))))\n",
      "Similarity: 0.8733, FOL: ∀x (Building(x) → (Exercise(x)  Stairs(x)))\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Processing NL Input: Trees absorb carbon dioxide, while cars emit carbon dioxide, and factories release carbon dioxide as a byproduct.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A person who designs and creates video games is called a game developer.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An apple is red or green, but not both.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Organisms that can produce their own food through photosynthesis, provide energy for other organisms, and do not consume other organisms are primary producers.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A device that converts thermal energy into electrical energy by using a temperature difference is a thermoelectric generator.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A dessert that is made from milk, sugar, and flavorings and is frozen is ice cream.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Birds migrate when the season changes and the temperature becomes unsuitable for their survival.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A food product is labeled organic if it is produced without synthetic pesticides and meets certain regulatory standards.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An electronic device that displays the time, receives radio signals for accurate timekeeping, and is powered by a battery is a radio-controlled clock.\n",
      "INFO:__main__:\n",
      "Processing NL Input: When a cell phone battery is depleted, it needs to be recharged.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A healthy diet consisting of a variety of fruits, vegetables, whole grains, and lean proteins promotes overall well-being and reduces the risk of chronic diseases.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A fruit is ripe if it is ready to be eaten and has reached its full flavor.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A book is a bestseller if it has sold over one million copies.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A place is considered a theater if it is a venue for live stage performances, often with a stage, curtains, and audience seating, and hosting plays, musicals, or other productions.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A beverage is classified as a soft drink if it does not contain alcohol and is typically carbonated.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A smartphone connects to the internet, makes calls, and sends messages.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A mountain forms from tectonic forces, has an elevation, and can be climbed.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An artistic expression that involves movement and is not a dance is either a theater performance or a circus act.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A bird can fly and not swim, or swim and not fly.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An object is buoyant if it floats on the surface of a liquid.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A bat is a mammal and can fly, while a turtle is a reptile and cannot fly.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A bicycle is a mountain bike if it has thick tires and is not designed for road use.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A red apple is sweet and a green apple is sour, while a yellow apple is a balance between sweet and sour.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Some animals are herbivores and eat only plants, while others are carnivores and eat only other animals.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A refrigerator preserves perishables but not electronics.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A battery stores electrical energy and provides power to devices.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vehicle is considered a motorcycle if it has two wheels and an engine.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A city has buildings, a park has trees, and a beach has sand.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An oven is used for baking and cooking food.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A beverage that is made from fermented grains, has a specific alcohol content, and is popular in a particular region is typically a beer or an ale.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Sun rises in the east, sets in the west, and shines during the day.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Wolves howl, while birds chirp.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A person is a volunteer if they offer their time and skills for a cause without expecting compensation.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vehicle is considered a bicycle if it has two wheels, is powered by human effort, and is ridden by a rider who sits on a seat and pedals.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A versatile musician plays different instruments, such as piano or guitar, and performs in various styles, like jazz or rock.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A polygon with four sides is called a quadrilateral.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A waterfall is a natural feature where water flows over a vertical drop or a series of steep drops, often found in mountainous areas or along rivers.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A student is an honor student if they have good grades and participate in extracurricular activities.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A game played on a rectangular surface, involves two teams, and has the objective of scoring points by putting a ball into the opposing team's goal is classified as soccer.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A thunderstorm occurs when warm air rises, creating instability in the atmosphere.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A fruit ripens when it receives ethylene gas, has reached its maturity, and is not exposed to cold temperatures.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A language x is considered a dead language if x is no longer spoken as a native language or used in daily communication.\n",
      "INFO:__main__:\n",
      "Processing NL Input: There exist shapes that are neither squares nor circles nor triangles.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A key opens a lock, but it does not close it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Qualitative Analysis ---\n",
      "Reference NL: There exist shapes that are neither squares nor circles nor triangles.\n",
      "Gold FOL: ∃x (Shape(x) ∧ ¬(Square(x) ∨ Circle(x) ∨ Triangle(x)))\n",
      "Hyperdimensional Ranking FOL: ∃x (Shape(x) ∧ ¬Squares(x) ∧ ¬Crowns(x) ∧ ¬Triangles(x))\n",
      "All Beam Hypotheses and Similarities:\n",
      "Similarity: 0.9160, FOL: ∃x (Shape(x) ∧ ¬Square(x) ∧ ¬Crown(x) ∧ ¬Triangle(x))\n",
      "Similarity: 0.9160, FOL: ∃x (Shape(x) ∧ ¬Square(x) ∧ ¬Crowd(x) ∧ ¬Triangle(x))\n",
      "Similarity: 0.7914, FOL: ∃x (Shape(x) ∧ ¬(Square(x) ∨ Circle(x) ∨ Triangle(x)))\n",
      "Similarity: 0.9471, FOL: ∃x (Shape(x) ∧ ¬Squares(x) ∧ ¬Crowns(x) ∧ ¬Triangles(x))\n",
      "Similarity: 0.8094, FOL: ∃x (Shape(x) ∧ ¬Square(x) ∨ Circle(x) ∨ Triangle(x))\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Processing NL Input: Rain occurs when clouds release water droplets.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Chemists study chemical reactions, while biologists examine living organisms.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A liquid turns into a gas if it reaches its boiling point.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A smartphone is water-resistant if it has a protective casing and sealed ports.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A computer can have a desktop, laptop, or tablet form factor, but not more than one form factor.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A musical instrument is considered versatile if it can produce a wide range of tones and is suitable for various musical styles.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A dancer performs on a stage.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A planet orbits a star only when it has a stable elliptical path, and it is not a moon.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A material is considered elastic if it returns to its original shape after being stretched or compressed.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A bicycle has two wheels, a frame, and a seat, and can be used for transportation or exercise.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Wearing a helmet reduces the risk of head injuries.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Some chairs are not made of wood.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A musical instrument x produces a pleasant sound if it is well-tuned and played by a skilled musician y.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Dolphins communicate with each other using sounds and body movements.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A bird is classified as migratory if it travels long distances, has specific breeding and wintering grounds, and follows a seasonal pattern.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Volcanoes can be dormant, active, or extinct, depending on their current state of eruption activity.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A movie is not both silent and having a soundtrack.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A meal is satisfying if it's flavorful, has a variety of textures, and doesn't leave one feeling overly full or still hungry.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A tree that grows in a desert environment and has deep roots is adapted to store water for extended periods of time.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A student passes a course when they attend regularly and score above the passing grade, or they may pass if they score exceptionally high on the final exam.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vibrant community organizes engaging events, promotes inclusivity, and fosters a sense of belonging among its members.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A robust security system detects intrusions, sends alerts to property owners, and ensures the safety of occupants within a building.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A dog that is trained to assist people with disabilities and has passed certification tests is a service dog.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A musical performance can be live and in-person, or it can be pre-recorded and streamed.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Snow forms at freezing temperatures, while rain occurs at temperatures above freezing.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A device that stores and retrieves data and can be connected to a computer is a storage device.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A movie can be classified as either a comedy, drama, or action film.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vehicle that can travel both on land and water is called an amphibious vehicle.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A triangle is equilateral or isosceles, but not both.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A device is a smartphone if it has a touchscreen interface, internet access, and can run applications for various purposes.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A ball is red or a cube is blue, but not both.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An animal that has feathers, lays eggs, and is warm-blooded is classified as a bird.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A product is in high demand if it is innovative, well-advertised, and solves a common problem.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A train and a bus are both means of public transportation.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A cake is sweet and is made from flour.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Sharks have cartilaginous skeletons, live in the ocean, and are carnivorous.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A smartphone facilitates communication and access to information, enabling users to stay connected and enhancing their productivity.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A laptop has a built-in keyboard and a display screen.\n",
      "INFO:__main__:\n",
      "Processing NL Input: If a food is spicy, it contains hot ingredients.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A square has four sides of equal length and four right angles.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A movie that is critically acclaimed has an engaging storyline and excellent acting.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A baker bakes bread.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Some athletes compete in individual sports, team sports, or both.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A triangle has three sides, whereas a square has four sides.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A dish is a dessert if it is sweet, served after a meal, and not part of the main course.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Some ice cream flavors are not sweet.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A student receives a scholarship if they demonstrate academic excellence or financial need.\n",
      "INFO:__main__:\n",
      "Processing NL Input: If a student studies diligently, they may pass an exam with a high score or fail due to external factors.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A cinema displays movies.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A solar panel generates electricity by capturing sunlight and converting it into electrical energy.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vaccine provides immunity against a specific pathogen by stimulating the immune system to recognize and respond to the pathogen without causing illness.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Mountains can influence climate by affecting wind patterns, precipitation, and temperature.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A laptop computer is portable, can run on battery power, and typically includes a built-in keyboard, touchpad, and display screen.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A student graduates from a university if they have completed their degree requirements and received a diploma from the university.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A dessert can be sweet or sour, a main course is savory, and a side dish can be salty or spicy.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A lawyer defends clients in criminal, civil, or family cases.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A zoo is home to a diverse assortment of animal species, providing them with habitats that closely resemble their natural environments.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A garden is thriving when it has a diverse range of plants and (receives adequate sunlight or benefits from fertile soil).\n",
      "INFO:__main__:\n",
      "Processing NL Input: Cyclists ride bicycles, motorcyclists ride motorcycles, and drivers operate cars, but pedestrians travel on foot.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A celestial object that orbits a planet is a moon.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Cats have fur, dogs have tails, and birds have feathers.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A smartphone can send text messages.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A student studies math xor history.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A number is even if it is divisible by two.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Museums display artifacts, and libraries lend books to visitors.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A musical performance is memorable if it showcases exceptional talent, unique stage presence, or an emotional connection with the audience.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A student studies mathematics, while a teacher teaches chemistry.\n",
      "INFO:__main__:\n",
      "Processing NL Input: If a plant is a type of grass, then it is not a tree.\n",
      "INFO:__main__:\n",
      "Processing NL Input: When a plant receives adequate sunlight, proper watering, and essential nutrients, it can thrive and grow healthily.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Two elements form a compound if they bond together through chemical reactions.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An electronic device is either in a powered-on state or a powered-off state, but not both at the same time.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An animal is a mammal if it has hair, gives birth to live young, and produces milk.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An exercise routine is effective when it targets different muscle groups and is performed regularly.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An airplane requires fuel to fly, while a hot air balloon relies on heated air for lift and a parachute uses air resistance to slow descent.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vehicle passes an emissions test if it is equipped with a catalytic converter and meets emission standards.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A weather condition characterized by the presence of ice crystals or snowflakes in the air and low visibility is called snowfall.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Rainforests are home to a variety of species, while cities are populated by humans and have infrastructure.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A plant x needs watering if the soil is dry and it is not a drought-tolerant species.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Medication can alleviate symptoms of certain illnesses.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Cacti store water in their thick stems, while ferns require constant moisture.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A clock can be either analog or digital.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A vessel that is designed to travel on water, carries people or goods, and is propelled by engines or sails is known as a boat.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A watch displays time using hands or a digital display.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A pencil is a writing instrument made of wood and graphite, but it is not a pen.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An animal is classified as a reptile if it has a cold-blooded metabolism, scaly skin, and usually lays eggs.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A professional athlete maintains a strict training schedule, adheres to a healthy diet, and prioritizes rest and recovery.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A desert receives very little precipitation and has extreme temperature fluctuations.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A healthy diet includes fruits, vegetables, and lean proteins, but avoids excessive sugar and saturated fats.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An atom is a metal or a non-metal, but not both.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An amphibian can live both on land and in water and undergoes metamorphosis during its life cycle.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A movie that has an engaging plot, well-developed characters, and excellent cinematography often receives positive reviews.\n",
      "INFO:__main__:\n",
      "Processing NL Input: A book can be borrowed from a library if its status is available.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An event that is not ticketed, is held outdoors, and features live music attracts a diverse crowd.\n",
      "INFO:__main__:\n",
      "Processing NL Input: An appliance x is a refrigerator if it is used for cooling and preserving food.\n",
      "INFO:__main__:\n",
      "Processing NL Input: Cats enjoy sleeping during the day and being active at night.\n",
      "INFO:__main__:\n",
      "Processing NL Input: In a basketball game, a team scores either two or three points per successful shot, but not both.\n",
      "INFO:__main__:Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Metrics ===\n",
      "Standard Decoding - Accuracy: 0.1750, F1 Score: 0.1750, Avg BLEU: 0.3916\n",
      "Constrained Decoding - Accuracy: 0.1750, F1 Score: 0.1750, Avg BLEU: 0.3867\n",
      "Hyperdimensional Ranking Decoding - Accuracy: 0.0700, F1 Score: 0.0700, Avg BLEU: 0.3037\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "compare_methods(subset_size=200, num_qualitative=3)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
